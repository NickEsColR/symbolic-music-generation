{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cfb3f6",
   "metadata": {},
   "source": [
    "# Replica del entrenamiento del modelo text2midi\n",
    "\n",
    "En este notebook se replica todo el proceso de entrenamiento presentado en el paper [Text2midi: Generating Symbolic Music from Captions](http://arxiv.org/abs/2412.16526).\n",
    "\n",
    "El modelo se puede encontrar perfectamente en hugging face en el [siguiente enlace](https://huggingface.co/amaai-lab/text2midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29d772",
   "metadata": {},
   "source": [
    "## Preparación del dataset SymphonyNet\n",
    "\n",
    "Primero se realiza el preprocesamiento del dataset usado para el pre entrenamiento. Se utiliza la librería music 21 para extraer los atributos de tempo, tonalidad, bpm e instrumentos de los archivos midi. Estos atributos sirven como placeholder de 10 frases diferentes, para simplificar usaremos una única plantilla. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa68be",
   "metadata": {},
   "source": [
    "### Prueba de music 21\n",
    "\n",
    "Primero se prueba que music 21 lea correctamente uno de los archivos midi antes de crear pseudo captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c5527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo encontrado: ../datasets/SymphonyNet_Dataset/classical/altnikol_befiehl_du_deine_wege_(c)icking-archive.mid\n",
      "\n",
      "Archivo MIDI cargado correctamente\n",
      "Tipo de objeto: <class 'music21.stream.base.Score'>\n",
      "\n",
      "Archivo MIDI cargado correctamente\n",
      "Tipo de objeto: <class 'music21.stream.base.Score'>\n"
     ]
    }
   ],
   "source": [
    "# Importar librería music21\n",
    "from music21 import converter, tempo, key\n",
    "import os\n",
    "\n",
    "# Definir la ruta del archivo MIDI\n",
    "midi_path = \"../datasets/SymphonyNet_Dataset/classical/altnikol_befiehl_du_deine_wege_(c)icking-archive.mid\"\n",
    "\n",
    "# Verificar que el archivo existe\n",
    "if os.path.exists(midi_path):\n",
    "    print(f\"Archivo encontrado: {midi_path}\")\n",
    "else:\n",
    "    print(f\"Archivo NO encontrado: {midi_path}\")\n",
    "    \n",
    "# Cargar el archivo MIDI\n",
    "score = converter.parse(midi_path)\n",
    "print(\"\\nArchivo MIDI cargado correctamente\")\n",
    "print(f\"Tipo de objeto: {type(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9a8e3",
   "metadata": {},
   "source": [
    "Ahora que sabemos que el archivo se leyó correctamente. Extraemos los atributos requeridos para el pre entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82678499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INFORMACIÓN BÁSICA DEL ARCHIVO MIDI\n",
      "============================================================\n",
      "\n",
      "Número de partes (tracks): 4\n",
      "Duración total: 1878.0 quarter notes\n",
      "Duración en segundos: nan segundos\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información básica del score\n",
    "print(\"=\" * 60)\n",
    "print(\"INFORMACIÓN BÁSICA DEL ARCHIVO MIDI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNúmero de partes (tracks): {len(score.parts)}\")\n",
    "print(f\"Duración total: {score.quarterLength} quarter notes\")\n",
    "print(f\"Duración en segundos: {score.seconds:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3006459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMEN DE ATRIBUTOS EXTRAÍDOS\n",
      "============================================================\n",
      "\n",
      "Atributos extraídos:\n",
      "  tempo_bpm: 120\n",
      "  key: D\n",
      "  key_mode: minor\n",
      "  time_signature: 4/4\n",
      "  instruments: Pan Flute, Trombone, English Horn, Bass, Alt, Tenor, Violoncello, Sopran\n",
      "  num_tracks: 4\n",
      "  duration_seconds: nan\n",
      "  num_notes: 8139\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Crear un resumen estructurado de los atributos extraídos\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DE ATRIBUTOS EXTRAÍDOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Función auxiliar para extraer atributos de forma robusta\n",
    "def extract_musical_attributes(score):\n",
    "    attributes = {\n",
    "        'tempo_bpm': None,\n",
    "        'key': None,\n",
    "        'key_mode': None,\n",
    "        'time_signature': None,\n",
    "        'instruments': set(),\n",
    "        'num_tracks': len(score.parts),\n",
    "        'duration_seconds': round(score.seconds, 2),\n",
    "        'num_notes': len(score.flatten().notes)\n",
    "    }\n",
    "    \n",
    "    # Tempo\n",
    "    tempo_marks = score.flatten().getElementsByClass(tempo.MetronomeMark)\n",
    "    if tempo_marks:\n",
    "        attributes['tempo_bpm'] = tempo_marks[0].number\n",
    "    else:\n",
    "        try:\n",
    "            estimated_tempo = score.flatten().metronomeMarkBoundaries()[0][-1]\n",
    "            attributes['tempo_bpm'] = estimated_tempo.number\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Tonalidad\n",
    "    key_sigs = score.flatten().getElementsByClass(key.Key)\n",
    "    if key_sigs:\n",
    "        attributes['key'] = key_sigs[0].tonic.name\n",
    "        attributes['key_mode'] = key_sigs[0].mode\n",
    "    else:\n",
    "        try:\n",
    "            analyzed_key = score.analyze('key')\n",
    "            attributes['key'] = analyzed_key.tonic.name\n",
    "            attributes['key_mode'] = analyzed_key.mode\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Compás\n",
    "    time_sigs = score.flatten().getElementsByClass('TimeSignature')\n",
    "    if time_sigs:\n",
    "        attributes['time_signature'] = f\"{time_sigs[0].numerator}/{time_sigs[0].denominator}\"\n",
    "    \n",
    "    # Instrumentos\n",
    "    for instrument in score.getInstruments() :\n",
    "        if instrument:\n",
    "            attributes['instruments'].add(instrument.bestName())\n",
    "\n",
    "    attributes['instruments'] = ', '.join(attributes['instruments']) if attributes['instruments'] else None\n",
    "    \n",
    "    return attributes\n",
    "\n",
    "# Extraer y mostrar atributos\n",
    "attributes = extract_musical_attributes(score)\n",
    "\n",
    "print(\"\\nAtributos extraídos:\")\n",
    "for k, value in attributes.items():\n",
    "    print(f\"  {k}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bc89ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSEUDO_TEMPLATE = f\"A musical piece in {{key}} {{key_mode}} key with a tempo of {{tempo_bpm}} BPM, time signature of {{time_signature}}, featuring instruments: {{instruments}}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e78b5182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A musical piece in D minor key with a tempo of 120 BPM, time signature of 4/4, featuring instruments: Pan Flute, Trombone, English Horn, Bass, Alt, Tenor, Violoncello, Sopran.\n"
     ]
    }
   ],
   "source": [
    "print(PSEUDO_TEMPLATE.format(**attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012915b6",
   "metadata": {},
   "source": [
    "Vemos que usando *music21* se obtiene los atributos musicales necesarios para generar las pseudo captions. Esta función se usara más adelante tras iterar por todos los archivos y generar un dataframe con los atributos **location** y **caption** para mantener los nombres del MidiCaps dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeacd64",
   "metadata": {},
   "source": [
    "### Generar el Dataframe para SymphonyNetDataset\n",
    "\n",
    "En esta sección se genera el dataframe que sera usado como pre entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b66c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolic-music-generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
